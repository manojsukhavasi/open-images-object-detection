{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "\n",
    "from datasets import OpenImagesDataset\n",
    "from retinanet import RetinaNet\n",
    "from loss import FocalLoss\n",
    "from utils.torch_utils import save_checkpoint, AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = OpenImagesDataset(root='./data/train',\n",
    "                            list_file ='./data/tmp/train_images_bbox.csv',\n",
    "                            transform=transform, train=True, input_size=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_dset, batch_size=3, shuffle=True, num_workers=8, collate_fn=train_dset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RetinaNet()\n",
    "net.load_state_dict(torch.load('./model/net.pth'))\n",
    "criterion = FocalLoss()\n",
    "net.cuda()\n",
    "criterion.cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-4, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, model, loss_fn, opt, epoch, interval):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    no_of_batches = int(train_loader.dataset.num_samples/train_loader.batch_size) + 1\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    for batch_idx, (inputs, loc_targets, cls_targets) in enumerate(train_loader):\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        inputs = inputs.cuda()\n",
    "        loc_targets = loc_targets.cuda()\n",
    "        cls_targets = cls_targets.cuda()\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loc_preds, cls_preds = model(inputs)\n",
    "        loss = loss_fn(loc_preds, loc_targets, cls_preds, cls_targets)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        if(batch_idx%interval == 0):\n",
    "            print(f'Train -> Batch : [{batch_idx}/{no_of_batches}]| Batch avg time :{batch_time.avg} \\\n",
    "            | Data_avg_time: {data_time.avg} | avg_loss: {train_loss/(batch_idx+1)}')\n",
    "            \n",
    "        if(batch_idx%(5000) == 0):\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'state_dict': net.state_dict(),\n",
    "                'best_val_loss': train_loss/(batch_idx+1),\n",
    "                'optimizer' : optimizer.state_dict()\n",
    "            }, is_best=True, fname=f'checkpoint_{epoch}_{batch_idx}.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manoj/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/manoj/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/manoj/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/manoj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Batch : [0/558327]| Batch avg time :2.4711053371429443             | Data_avg_time: 1.101675271987915 | avg_loss: 4.198276042938232\n",
      "Train -> Batch : [100/558327]| Batch avg time :1.2880447264945154             | Data_avg_time: 0.02347696653687128 | avg_loss: 6.6026411056518555\n",
      "Train -> Batch : [200/558327]| Batch avg time :1.2801134693088816             | Data_avg_time: 0.01420973426667019 | avg_loss: 6.595991611480713\n",
      "Train -> Batch : [300/558327]| Batch avg time :1.2787376519453486             | Data_avg_time: 0.011103416994164552 | avg_loss: 6.398797512054443\n",
      "Train -> Batch : [400/558327]| Batch avg time :1.2777136222382732             | Data_avg_time: 0.009557149059457374 | avg_loss: 6.264936447143555\n",
      "Train -> Batch : [500/558327]| Batch avg time :1.2783410006654476             | Data_avg_time: 0.00865890784653837 | avg_loss: 6.201728820800781\n",
      "Train -> Batch : [600/558327]| Batch avg time :1.2772861479126079             | Data_avg_time: 0.008036359177651302 | avg_loss: 6.1882123947143555\n",
      "Train -> Batch : [700/558327]| Batch avg time :1.2777506492277355             | Data_avg_time: 0.007589053155352148 | avg_loss: 6.181631565093994\n",
      "Train -> Batch : [800/558327]| Batch avg time :1.2767844575174738             | Data_avg_time: 0.007257976484358236 | avg_loss: 6.20937967300415\n",
      "Train -> Batch : [900/558327]| Batch avg time :1.276884944007611             | Data_avg_time: 0.007010451167590345 | avg_loss: 6.158130168914795\n",
      "Train -> Batch : [1000/558327]| Batch avg time :1.2769967459298515             | Data_avg_time: 0.006799683108791843 | avg_loss: 6.140501499176025\n",
      "Train -> Batch : [1100/558327]| Batch avg time :1.2771410439687898             | Data_avg_time: 0.00793096415028585 | avg_loss: 6.115582466125488\n",
      "Train -> Batch : [1200/558327]| Batch avg time :1.275893215732114             | Data_avg_time: 0.007670361235377989 | avg_loss: 6.104595184326172\n",
      "Train -> Batch : [1300/558327]| Batch avg time :1.2752121962738623             | Data_avg_time: 0.007454014117675593 | avg_loss: 6.1110453605651855\n",
      "Train -> Batch : [1400/558327]| Batch avg time :1.274979514959963             | Data_avg_time: 0.007274488480409327 | avg_loss: 6.062283039093018\n"
     ]
    }
   ],
   "source": [
    "train_one_epoch(train_loader, net, criterion, optimizer, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
